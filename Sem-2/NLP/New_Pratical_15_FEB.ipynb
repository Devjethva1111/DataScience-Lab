{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d59c2962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('As', 'IN'), ('a', 'DT'), ('text-based', 'JJ'), ('AI', 'NNP'), ('language', 'NN'), ('model', 'NN'), (',', ','), ('I', 'PRP'), ('ca', 'MD'), (\"n't\", 'RB'), ('produce', 'VB'), ('American', 'JJ'), ('Sign', 'NNP'), ('Language', 'NNP'), ('(', '('), ('ASL', 'NNP'), (')', ')'), ('directly', 'RB'), ('.', '.'), ('However', 'RB'), (',', ','), ('I', 'PRP'), ('can', 'MD'), ('describe', 'VB'), ('a', 'DT'), ('scene', 'NN'), ('or', 'CC'), ('provide', 'VB'), ('instructions', 'NNS'), ('for', 'IN'), ('a', 'DT'), ('sign', 'NN'), ('language', 'NN'), ('interpreter', 'NN'), ('to', 'TO'), ('convey', 'VB'), ('in', 'IN'), ('ASL.Imagine', 'NNP'), ('a', 'DT'), ('sunny', 'JJ'), ('day', 'NN'), ('at', 'IN'), ('the', 'DT'), ('beach', 'NN'), ('.', '.'), ('The', 'DT'), ('sand', 'NN'), ('is', 'VBZ'), ('warm', 'JJ'), ('beneath', 'IN'), ('your', 'PRP$'), ('feet', 'NNS'), ('as', 'IN'), ('you', 'PRP'), ('walk', 'VBP'), ('toward', 'IN'), ('the', 'DT'), ('sparkling', 'VBG'), ('blue', 'JJ'), ('ocean', 'NN'), ('.', '.'), ('Seagulls', 'NNP'), ('soar', 'JJ'), ('overhead', 'NN'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('sound', 'NN'), ('of', 'IN'), ('waves', 'NNS'), ('crashing', 'VBG'), ('against', 'IN'), ('the', 'DT'), ('shore', 'NN'), ('fills', 'VBZ'), ('the', 'DT'), ('air', 'NN'), ('.', '.'), ('You', 'PRP'), ('spread', 'VBP'), ('out', 'RP'), ('a', 'DT'), ('colorful', 'JJ'), ('beach', 'NN'), ('towel', 'NN'), ('and', 'CC'), ('lie', 'VB'), ('down', 'RB'), ('to', 'TO'), ('soak', 'VB'), ('up', 'RP'), ('the', 'DT'), ('sun', 'NN'), (\"'s\", 'POS'), ('rays', 'NNS'), (',', ','), ('feeling', 'VBG'), ('completely', 'RB'), ('relaxed', 'VBN'), ('and', 'CC'), ('at', 'IN'), ('peace.In', 'JJ'), ('ASL', 'NNP'), (',', ','), ('this', 'DT'), ('scene', 'NN'), ('could', 'MD'), ('be', 'VB'), ('conveyed', 'VBN'), ('by', 'IN'), ('signing', 'VBG'), ('various', 'JJ'), ('gestures', 'NNS'), ('and', 'CC'), ('movements', 'NNS'), ('to', 'TO'), ('represent', 'VB'), ('the', 'DT'), ('beach', 'NN'), (',', ','), ('the', 'DT'), ('sun', 'NN'), (',', ','), ('walking', 'NN'), (',', ','), ('lying', 'VBG'), ('down', 'RP'), (',', ','), ('seagulls', 'NNS'), ('flying', 'VBG'), (',', ','), ('waves', 'NNS'), ('crashing', 'VBG'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('feeling', 'NN'), ('of', 'IN'), ('relaxation', 'NN'), ('.', '.'), ('An', 'DT'), ('ASL', 'JJ'), ('interpreter', 'NN'), ('would', 'MD'), ('use', 'VB'), ('their', 'PRP$'), ('expertise', 'NN'), ('to', 'TO'), ('convey', 'VB'), ('the', 'DT'), ('message', 'NN'), ('effectively', 'RB'), ('in', 'IN'), ('sign', 'JJ'), ('language', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = \"As a text-based AI language model, I can't produce American Sign Language (ASL) directly. However, I can describe a scene or provide instructions for a sign language interpreter to convey in ASL.Imagine a sunny day at the beach. The sand is warm beneath your feet as you walk toward the sparkling blue ocean. Seagulls soar overhead, and the sound of waves crashing against the shore fills the air. You spread out a colorful beach towel and lie down to soak up the sun's rays, feeling completely relaxed and at peace.In ASL, this scene could be conveyed by signing various gestures and movements to represent the beach, the sun, walking, lying down, seagulls flying, waves crashing, and the feeling of relaxation. An ASL interpreter would use their expertise to convey the message effectively in sign language.\"\n",
    "words = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(words)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39bf65b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\devje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e69c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5e06af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams\n",
      "[('As', 'a'), ('a', 'text-based'), ('text-based', 'AI'), ('AI', 'language'), ('language', 'model'), ('model', ','), (',', 'I'), ('I', 'ca'), ('ca', \"n't\"), (\"n't\", 'produce'), ('produce', 'American'), ('American', 'Sign'), ('Sign', 'Language'), ('Language', '('), ('(', 'ASL'), ('ASL', ')'), (')', 'directly'), ('directly', '.'), ('.', 'However'), ('However', ','), (',', 'I'), ('I', 'can'), ('can', 'describe'), ('describe', 'a'), ('a', 'scene'), ('scene', 'or'), ('or', 'provide'), ('provide', 'instructions'), ('instructions', 'for'), ('for', 'a'), ('a', 'sign'), ('sign', 'language'), ('language', 'interpreter'), ('interpreter', 'to'), ('to', 'convey'), ('convey', 'in'), ('in', 'ASL.Imagine'), ('ASL.Imagine', 'a'), ('a', 'sunny'), ('sunny', 'day'), ('day', 'at'), ('at', 'the'), ('the', 'beach'), ('beach', '.'), ('.', 'The'), ('The', 'sand'), ('sand', 'is'), ('is', 'warm'), ('warm', 'beneath'), ('beneath', 'your'), ('your', 'feet'), ('feet', 'as'), ('as', 'you'), ('you', 'walk'), ('walk', 'toward'), ('toward', 'the'), ('the', 'sparkling'), ('sparkling', 'blue'), ('blue', 'ocean'), ('ocean', '.'), ('.', 'Seagulls'), ('Seagulls', 'soar'), ('soar', 'overhead'), ('overhead', ','), (',', 'and'), ('and', 'the'), ('the', 'sound'), ('sound', 'of'), ('of', 'waves'), ('waves', 'crashing'), ('crashing', 'against'), ('against', 'the'), ('the', 'shore'), ('shore', 'fills'), ('fills', 'the'), ('the', 'air'), ('air', '.'), ('.', 'You'), ('You', 'spread'), ('spread', 'out'), ('out', 'a'), ('a', 'colorful'), ('colorful', 'beach'), ('beach', 'towel'), ('towel', 'and'), ('and', 'lie'), ('lie', 'down'), ('down', 'to'), ('to', 'soak'), ('soak', 'up'), ('up', 'the'), ('the', 'sun'), ('sun', \"'s\"), (\"'s\", 'rays'), ('rays', ','), (',', 'feeling'), ('feeling', 'completely'), ('completely', 'relaxed'), ('relaxed', 'and'), ('and', 'at'), ('at', 'peace.In'), ('peace.In', 'ASL'), ('ASL', ','), (',', 'this'), ('this', 'scene'), ('scene', 'could'), ('could', 'be'), ('be', 'conveyed'), ('conveyed', 'by'), ('by', 'signing'), ('signing', 'various'), ('various', 'gestures'), ('gestures', 'and'), ('and', 'movements'), ('movements', 'to'), ('to', 'represent'), ('represent', 'the'), ('the', 'beach'), ('beach', ','), (',', 'the'), ('the', 'sun'), ('sun', ','), (',', 'walking'), ('walking', ','), (',', 'lying'), ('lying', 'down'), ('down', ','), (',', 'seagulls'), ('seagulls', 'flying'), ('flying', ','), (',', 'waves'), ('waves', 'crashing'), ('crashing', ','), (',', 'and'), ('and', 'the'), ('the', 'feeling'), ('feeling', 'of'), ('of', 'relaxation'), ('relaxation', '.'), ('.', 'An'), ('An', 'ASL'), ('ASL', 'interpreter'), ('interpreter', 'would'), ('would', 'use'), ('use', 'their'), ('their', 'expertise'), ('expertise', 'to'), ('to', 'convey'), ('convey', 'the'), ('the', 'message'), ('message', 'effectively'), ('effectively', 'in'), ('in', 'sign'), ('sign', 'language'), ('language', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Create Bigrams\n",
    "bigrams =list(bigrams(words))\n",
    "\n",
    "#print the bigrams\n",
    "print(\"Bigrams\")\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae0c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_freq = nltk.FreqDist(words)\n",
    "bigram_freq = nltk.FreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a934fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03fe8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and part-of-speech tagging\n",
    "tokens = word_tokenize(text)\n",
    "tags = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adeae74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-word phrases with adjectives:\n",
      "['text-based AI', 'American Sign', 'sunny day', 'blue ocean', 'soar overhead', 'colorful beach', 'peace.In ASL', 'various gestures', 'ASL interpreter', 'sign language']\n"
     ]
    }
   ],
   "source": [
    "# Extract two-word phrases with adjectives\n",
    "adjective_noun_phrases = [f\"{word} {next_word}\" for (word, tag), (next_word, next_tag) in bigrams(tags)\n",
    "                          if tag.startswith('JJ') and next_tag.startswith('NN')]\n",
    "\n",
    "# Print the results\n",
    "print(\"Two-word phrases with adjectives:\")\n",
    "print(adjective_noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26ad7d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"n't\", 'produce')\n",
      "('sunny', 'day')\n",
      "('blue', 'ocean')\n",
      "('soar', 'overhead')\n",
      "('colorful', 'beach')\n",
      "('completely', 'relaxed')\n",
      "('various', 'gestures')\n",
      "('ASL', 'interpreter')\n",
      "('sign', 'language')\n"
     ]
    }
   ],
   "source": [
    "def filter_bigrams(tags):\n",
    "    filtered_bigrams = []\n",
    "    for i in range(len(tags) - 1):\n",
    "        first_word, first_tag = tags[i]\n",
    "        second_word, second_tag = tags[i + 1]\n",
    "        \n",
    "        if (first_tag.startswith('JJ') and second_tag in ['NN', 'NNS']) \\\n",
    "            or (first_tag in ['RB', 'RBR', 'RBS'] and second_tag.startswith('JJ') and not (second_tag == 'NN' or second_tag == 'NNS')) \\\n",
    "            or (first_tag.startswith('JJ') and second_tag.startswith('JJ') and not (second_tag == 'NN' or second_tag == 'NNS')) \\\n",
    "            or ((first_tag == 'NN' or first_tag == 'NNS') and second_tag.startswith('JJ') and not (second_tag == 'NN' or second_tag == 'NNS')) \\\n",
    "            or (first_tag in ['RB', 'RBR', 'RBS'] and second_tag.startswith('VB') and second_tag != 'NNS'):\n",
    "            filtered_bigrams.append((first_word, second_word))\n",
    "    return filtered_bigrams\n",
    "\n",
    "filtered_bigrams = filter_bigrams(tags)\n",
    "\n",
    "for bigram in filtered_bigrams:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "377dfe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMI Matrix:\n",
      "PMI(produce | n't) = 2.1972\n",
      "PMI(day | sunny) = 2.1972\n",
      "PMI(ocean | blue) = 2.1972\n",
      "PMI(overhead | soar) = 2.1972\n",
      "PMI(beach | colorful) = 2.1972\n",
      "PMI(relaxed | completely) = 2.1972\n",
      "PMI(gestures | various) = 2.1972\n",
      "PMI(interpreter | ASL) = 2.1972\n",
      "PMI(language | sign) = 2.1972\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Given bigrams\n",
    "bigrams = [(\"n't\", 'produce'),\n",
    "           ('sunny', 'day'),\n",
    "           ('blue', 'ocean'),\n",
    "           ('soar', 'overhead'),\n",
    "           ('colorful', 'beach'),\n",
    "           ('completely', 'relaxed'),\n",
    "           ('various', 'gestures'),\n",
    "           ('ASL', 'interpreter'),\n",
    "           ('sign', 'language')]\n",
    "\n",
    "# Count occurrences of each bigram\n",
    "bigram_counts = defaultdict(int)\n",
    "for bigram in bigrams:\n",
    "    bigram_counts[bigram] += 1\n",
    "\n",
    "# Calculate probabilities\n",
    "total_bigrams = sum(bigram_counts.values())\n",
    "word_probs = defaultdict(float)\n",
    "for bigram, count in bigram_counts.items():\n",
    "    word1, word2 = bigram\n",
    "    word_probs[word1] += count\n",
    "    word_probs[word2] += count\n",
    "\n",
    "for word in word_probs:\n",
    "    word_probs[word] /= total_bigrams\n",
    "\n",
    "# Calculate PMI\n",
    "pmi_matrix = {}\n",
    "for bigram, count in bigram_counts.items():\n",
    "    word1, word2 = bigram\n",
    "    joint_prob = count / total_bigrams\n",
    "    pmi = math.log(joint_prob / (word_probs[word1] * word_probs[word2]))\n",
    "    if word1 not in pmi_matrix:\n",
    "        pmi_matrix[word1] = {}\n",
    "    pmi_matrix[word1][word2] = pmi\n",
    "\n",
    "# Display PMI matrix\n",
    "print(\"PMI Matrix:\")\n",
    "for word1, word2_pmi in pmi_matrix.items():\n",
    "    for word2, pmi in word2_pmi.items():\n",
    "        print(f\"PMI({word2} | {word1}) = {pmi:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcdedba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
