{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08866e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[')', ',', '.', ':', 'ADJ', 'ADV', 'CC', 'CD', 'DT', 'FW', 'IN', 'MD', 'N', 'POS', 'PRO', 'TO', 'V', 'WDT', 'WP', '``']\n",
      "{'DT': 19, 'N': 17, 'PRO': 3, 'CD': 7, ',': 1, 'ADV': 1, 'ADJ': 3}\n",
      "{'V': 2}\n",
      "i= 1  and output= V\n",
      "i= 2  and output= ADJ\n",
      "Fraction of errors (Baseline) : 0.0\n",
      "Fraction of errors (Viterbi): 0.0\n",
      "Tags suggested by Baseline Algorithm: ['N', 'V', 'ADJ', 'N']\n",
      "Tags suggested by Viterbi Algorithm: ['N', 'V', 'ADJ', 'N']\n",
      "Correct tags: ['N', 'V', 'ADJ', 'N']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division #To avoid integer division\n",
    "from operator import itemgetter\n",
    "###Training Phase###\n",
    "\n",
    "with open(\"wsj_training.txt\", \"r\") as myfile:\n",
    "    tr_str = myfile.read()\n",
    "tr_li = tr_str.split()\n",
    "num_words_train = len(tr_li)\n",
    "\n",
    "train_li_words = ['']\n",
    "train_li_words*= num_words_train\n",
    "\n",
    "train_li_tags = ['']\n",
    "train_li_tags*= num_words_train\n",
    "\n",
    "noun_reduced_list = ['NN','NNS','NNP','NNPS']\n",
    "verb_reduced_list = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "adjec_reduced_list = ['JJ', 'JJR', 'JJS']\n",
    "adv_reduced_list = ['RB', 'RBR', 'RBS']\n",
    "pronoun_reduced_list = ['PRP', 'PRP$', 'RP']\n",
    "\n",
    "for i in range(num_words_train):\n",
    "    temp_li = tr_li[i].split(\"/\")\n",
    "    train_li_words[i] = temp_li[0]\n",
    "    if temp_li[1] in noun_reduced_list:\n",
    "        train_li_tags[i] = 'N'\n",
    "    elif temp_li[1] in verb_reduced_list:\n",
    "        train_li_tags[i] = 'V'\n",
    "    elif temp_li[1] in adjec_reduced_list:\n",
    "        train_li_tags[i] = 'ADJ'\n",
    "    elif temp_li[1] in adv_reduced_list:\n",
    "        train_li_tags[i] = 'ADV'        \n",
    "    elif temp_li[1] in pronoun_reduced_list:\n",
    "        train_li_tags[i] = 'PRO'\n",
    "    else:\n",
    "        train_li_tags[i] = temp_li[1]\n",
    "\n",
    "k = sorted(list(set(train_li_tags)))\n",
    "print (k)\n",
    "dict2_tag_follow_tag_ = {}\n",
    "\"\"\"Nested dictionary to store the transition probabilities\n",
    "each tag A is a key of the outer dictionary\n",
    "the inner dictionary is the corresponding value\n",
    "The inner dictionary's key is the tag B following A\n",
    "and the corresponding value is the number of times B follows A\n",
    "\"\"\"\n",
    "\n",
    "dict2_word_tag = {}\n",
    "\"\"\"Nested dictionary to store the emission probabilities.\n",
    "Each word W is a key of the outer dictionary\n",
    "The inner dictionary is the corresponding value\n",
    "The inner dictionary's key is the tag A of the word W\n",
    "and the corresponding value is the number of times A is a tag of W\n",
    "\"\"\"\n",
    "\n",
    "dict_word_tag_baseline = {}\n",
    "#Dictionary with word as key and its most frequent tag as value\n",
    "\n",
    "for i in range(num_words_train-1):\n",
    "    outer_key = train_li_tags[i]\n",
    "    inner_key = train_li_tags[i+1]\n",
    "    dict2_tag_follow_tag_[outer_key]=dict2_tag_follow_tag_.get(outer_key,{})\n",
    "    dict2_tag_follow_tag_[outer_key][inner_key] = dict2_tag_follow_tag_[outer_key].get(inner_key,0)\n",
    "    dict2_tag_follow_tag_[outer_key][inner_key]+=1\n",
    "\n",
    "    outer_key = train_li_words[i]\n",
    "    inner_key = train_li_tags[i]\n",
    "    dict2_word_tag[outer_key]=dict2_word_tag.get(outer_key,{})\n",
    "    dict2_word_tag[outer_key][inner_key] = dict2_word_tag[outer_key].get(inner_key,0)\n",
    "    dict2_word_tag[outer_key][inner_key]+=1\n",
    "\n",
    "\n",
    "\"\"\"The 1st token is indicated by being the 1st word of a senetence, that is the word after period(.)\n",
    "Adjusting for the fact that the first word of the document is not accounted for that way\n",
    "\"\"\"\n",
    "\n",
    "dict2_tag_follow_tag_['.'] = dict2_tag_follow_tag_.get('.',{})\n",
    "dict2_tag_follow_tag_['.'][train_li_tags[0]] = dict2_tag_follow_tag_['.'].get(train_li_tags[0],0)\n",
    "dict2_tag_follow_tag_['.'][train_li_tags[0]]+=1\n",
    "\n",
    "\n",
    "print (dict2_tag_follow_tag_['IN'])\n",
    "print (dict2_word_tag['made'])\n",
    "\n",
    "last_index = num_words_train-1\n",
    "\n",
    "#Accounting for the last word-tag pair\n",
    "outer_key = train_li_words[last_index]\n",
    "inner_key = train_li_tags[last_index]\n",
    "dict2_word_tag[outer_key]=dict2_word_tag.get(outer_key,{})\n",
    "dict2_word_tag[outer_key][inner_key] = dict2_word_tag[outer_key].get(inner_key,0)\n",
    "dict2_word_tag[outer_key][inner_key]+=1\n",
    "\n",
    "\n",
    "\"\"\"Converting counts to probabilities in the two nested dictionaries\n",
    "& also converting the nested dictionaries to outer dictionary with inner sorted lists\n",
    "\"\"\"\n",
    "for key in dict2_tag_follow_tag_:\n",
    "    di = dict2_tag_follow_tag_[key]\n",
    "    s = sum(di.values())\n",
    "    for innkey in di:\n",
    "        di[innkey] /= s\n",
    "    di = di.items()\n",
    "    di = sorted(di,key=lambda x: x[0])\n",
    "    dict2_tag_follow_tag_[key] = di\n",
    "\n",
    "for key in dict2_word_tag:\n",
    "    di = dict2_word_tag[key]\n",
    "    dict_word_tag_baseline[key] = max(di, key=di.get)\n",
    "    s = sum(di.values())\n",
    "    for innkey in di:\n",
    "        di[innkey] /= s\n",
    "    di = di.items()\n",
    "    di = sorted(di,key=lambda x: x[0])\n",
    "    dict2_word_tag[key] = di\n",
    "\n",
    "###Testing Phase###    \n",
    "\n",
    "with open(\"test.txt\", \"r\") as myfile:\n",
    "    te_str = myfile.read()\n",
    "\n",
    "te_li = te_str.split()\n",
    "num_words_test = len(te_li)\n",
    "\n",
    "test_li_words = ['']\n",
    "test_li_words*= num_words_test\n",
    "\n",
    "test_li_tags = ['']\n",
    "test_li_tags*= num_words_test\n",
    "\n",
    "output_li = ['']\n",
    "output_li*= num_words_test\n",
    "\n",
    "output_li_baseline = ['']\n",
    "output_li_baseline*= num_words_test\n",
    "\n",
    "num_errors = 0\n",
    "num_errors_baseline = 0\n",
    "\n",
    "for i in range(num_words_test):\n",
    "    temp_li = te_li[i].split(\"/\")\n",
    "    test_li_words[i] = temp_li[0]\n",
    "    if temp_li[1] in noun_reduced_list:\n",
    "        test_li_tags[i] = 'N'\n",
    "    elif temp_li[1] in verb_reduced_list:\n",
    "        test_li_tags[i] = 'V'\n",
    "    elif temp_li[1] in adjec_reduced_list:\n",
    "        test_li_tags[i] = 'ADJ'\n",
    "    elif temp_li[1] in adv_reduced_list:\n",
    "        test_li_tags[i] = 'ADV'        \n",
    "    elif temp_li[1] in pronoun_reduced_list:\n",
    "        test_li_tags[i] = 'PRO'\n",
    "    else:\n",
    "        test_li_tags[i] = temp_li[1]\n",
    "\n",
    "\n",
    "    output_li_baseline[i] = dict_word_tag_baseline.get(temp_li[0],'')\n",
    "    #If unknown word - tag = 'N'\n",
    "    if output_li_baseline[i]=='':\n",
    "        output_li_baseline[i]='N'\n",
    "\n",
    "    if output_li_baseline[i]!=test_li_tags[i]:\n",
    "        num_errors_baseline+=1\n",
    "    \n",
    "    if i==0:    #Accounting for the 1st word in the test document for the Viterbi\n",
    "        di_transition_probs = dict2_tag_follow_tag_['.']\n",
    "    else:\n",
    "        di_transition_probs = dict2_tag_follow_tag_[output_li[i-1]]\n",
    "        \n",
    "    di_emission_probs = dict2_word_tag.get(test_li_words[i],'')\n",
    "\n",
    "    #If unknown word  - tag = 'N'\n",
    "    if di_emission_probs=='':\n",
    "        output_li[i]='N'\n",
    "        \n",
    "    else:\n",
    "        max_prod_prob = 0\n",
    "        counter_trans = 0\n",
    "        counter_emis =0\n",
    "        prod_prob = 0\n",
    "        while counter_trans < len(di_transition_probs) and counter_emis < len(di_emission_probs):\n",
    "            tag_tr = di_transition_probs[counter_trans][0]\n",
    "            tag_em = di_emission_probs[counter_emis][0]\n",
    "            if tag_tr < tag_em:\n",
    "                counter_trans+=1\n",
    "            elif tag_tr > tag_em:\n",
    "                counter_emis+=1\n",
    "            else:\n",
    "                prod_prob = di_transition_probs[counter_trans][1] * di_emission_probs[counter_emis][1]\n",
    "                if prod_prob > max_prod_prob:\n",
    "                    max_prod_prob = prod_prob\n",
    "                    output_li[i] = tag_tr\n",
    "                    print (\"i=\",i,\" and output=\",output_li[i])\n",
    "                counter_trans+=1\n",
    "                counter_emis+=1    \n",
    "\n",
    "    if output_li[i]=='': #In case there are no matching entries between the transition tags and emission tags, we choose the most frequent emission tag\n",
    "        output_li[i] = max(di_emission_probs,key=itemgetter(1))[0]  \n",
    "        \n",
    "    if output_li[i]!=test_li_tags[i]:\n",
    "        num_errors+=1\n",
    "\n",
    "                    \n",
    "print (\"Fraction of errors (Baseline) :\",(num_errors_baseline/num_words_test))\n",
    "print (\"Fraction of errors (Viterbi):\",(num_errors/num_words_test))\n",
    "\n",
    "\n",
    "\n",
    "print (\"Tags suggested by Baseline Algorithm:\", output_li_baseline)\n",
    "\n",
    "print (\"Tags suggested by Viterbi Algorithm:\", output_li)\n",
    "\n",
    "print (\"Correct tags:\",test_li_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a014c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55ed221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aa</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aaa</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aah</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aahed</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aahing</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370095</th>\n",
       "      <td>370097</td>\n",
       "      <td>zwinglianism</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370096</th>\n",
       "      <td>370098</td>\n",
       "      <td>zwinglianist</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370097</th>\n",
       "      <td>370099</td>\n",
       "      <td>zwitter</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370098</th>\n",
       "      <td>370100</td>\n",
       "      <td>zwitterion</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370099</th>\n",
       "      <td>370101</td>\n",
       "      <td>zwitterionic</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0          word pos_tag\n",
       "0                0            aa      NN\n",
       "1                1           aaa      NN\n",
       "2                2           aah      NN\n",
       "3                3         aahed     VBN\n",
       "4                4        aahing     VBG\n",
       "...            ...           ...     ...\n",
       "370095      370097  zwinglianism      NN\n",
       "370096      370098  zwinglianist      NN\n",
       "370097      370099       zwitter      NN\n",
       "370098      370100    zwitterion      NN\n",
       "370099      370101  zwitterionic      NN\n",
       "\n",
       "[370100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"H:\\DataScience-Lab\\Sem-2\\NLP\\Files\\words_pos.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b569c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[')', ',', '.', ':', 'ADJ', 'ADV', 'CC', 'CD', 'DT', 'FW', 'IN', 'MD', 'N', 'POS', 'PRO', 'TO', 'V', 'WDT', 'WP', '``']\n",
      "{'DT': 19, 'N': 17, 'PRO': 3, 'CD': 7, ',': 1, 'ADV': 1, 'ADJ': 3}\n",
      "{'V': 2}\n",
      "i= 1  and output= V\n",
      "i= 2  and output= ADJ\n",
      "Fraction of errors (Baseline) : 0.0\n",
      "Fraction of errors (Viterbi): 0.0\n",
      "Tags suggested by Baseline Algorithm: ['N', 'V', 'ADJ', 'N']\n",
      "Tags suggested by Viterbi Algorithm: ['N', 'V', 'ADJ', 'N']\n",
      "Correct tags: ['N', 'V', 'ADJ', 'N']\n"
     ]
    }
   ],
   "source": [
    "tr_li = tr_str.split()\n",
    "num_words_train = len(tr_li)\n",
    "\n",
    "train_li_words = ['']\n",
    "train_li_words*= num_words_train\n",
    "\n",
    "train_li_tags = ['']\n",
    "train_li_tags*= num_words_train\n",
    "\n",
    "noun_reduced_list = ['NN','NNS','NNP','NNPS']\n",
    "verb_reduced_list = ['VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "adjec_reduced_list = ['JJ', 'JJR', 'JJS']\n",
    "adv_reduced_list = ['RB', 'RBR', 'RBS']\n",
    "pronoun_reduced_list = ['PRP', 'PRP$', 'RP']\n",
    "\n",
    "for i in range(num_words_train):\n",
    "    temp_li = tr_li[i].split(\"/\")\n",
    "    train_li_words[i] = temp_li[0]\n",
    "    if temp_li[1] in noun_reduced_list:\n",
    "        train_li_tags[i] = 'N'\n",
    "    elif temp_li[1] in verb_reduced_list:\n",
    "        train_li_tags[i] = 'V'\n",
    "    elif temp_li[1] in adjec_reduced_list:\n",
    "        train_li_tags[i] = 'ADJ'\n",
    "    elif temp_li[1] in adv_reduced_list:\n",
    "        train_li_tags[i] = 'ADV'        \n",
    "    elif temp_li[1] in pronoun_reduced_list:\n",
    "        train_li_tags[i] = 'PRO'\n",
    "    else:\n",
    "        train_li_tags[i] = temp_li[1]\n",
    "\n",
    "k = sorted(list(set(train_li_tags)))\n",
    "print (k)\n",
    "dict2_tag_follow_tag_ = {}\n",
    "\"\"\"Nested dictionary to store the transition probabilities\n",
    "each tag A is a key of the outer dictionary\n",
    "the inner dictionary is the corresponding value\n",
    "The inner dictionary's key is the tag B following A\n",
    "and the corresponding value is the number of times B follows A\n",
    "\"\"\"\n",
    "\n",
    "dict2_word_tag = {}\n",
    "\"\"\"Nested dictionary to store the emission probabilities.\n",
    "Each word W is a key of the outer dictionary\n",
    "The inner dictionary is the corresponding value\n",
    "The inner dictionary's key is the tag A of the word W\n",
    "and the corresponding value is the number of times A is a tag of W\n",
    "\"\"\"\n",
    "\n",
    "dict_word_tag_baseline = {}\n",
    "#Dictionary with word as key and its most frequent tag as value\n",
    "\n",
    "for i in range(num_words_train-1):\n",
    "    outer_key = train_li_tags[i]\n",
    "    inner_key = train_li_tags[i+1]\n",
    "    dict2_tag_follow_tag_[outer_key]=dict2_tag_follow_tag_.get(outer_key,{})\n",
    "    dict2_tag_follow_tag_[outer_key][inner_key] = dict2_tag_follow_tag_[outer_key].get(inner_key,0)\n",
    "    dict2_tag_follow_tag_[outer_key][inner_key]+=1\n",
    "\n",
    "    outer_key = train_li_words[i]\n",
    "    inner_key = train_li_tags[i]\n",
    "    dict2_word_tag[outer_key]=dict2_word_tag.get(outer_key,{})\n",
    "    dict2_word_tag[outer_key][inner_key] = dict2_word_tag[outer_key].get(inner_key,0)\n",
    "    dict2_word_tag[outer_key][inner_key]+=1\n",
    "\n",
    "\n",
    "\"\"\"The 1st token is indicated by being the 1st word of a senetence, that is the word after period(.)\n",
    "Adjusting for the fact that the first word of the document is not accounted for that way\n",
    "\"\"\"\n",
    "\n",
    "dict2_tag_follow_tag_['.'] = dict2_tag_follow_tag_.get('.',{})\n",
    "dict2_tag_follow_tag_['.'][train_li_tags[0]] = dict2_tag_follow_tag_['.'].get(train_li_tags[0],0)\n",
    "dict2_tag_follow_tag_['.'][train_li_tags[0]]+=1\n",
    "\n",
    "\n",
    "print (dict2_tag_follow_tag_['IN'])\n",
    "print (dict2_word_tag['made'])\n",
    "\n",
    "last_index = num_words_train-1\n",
    "\n",
    "#Accounting for the last word-tag pair\n",
    "outer_key = train_li_words[last_index]\n",
    "inner_key = train_li_tags[last_index]\n",
    "dict2_word_tag[outer_key]=dict2_word_tag.get(outer_key,{})\n",
    "dict2_word_tag[outer_key][inner_key] = dict2_word_tag[outer_key].get(inner_key,0)\n",
    "dict2_word_tag[outer_key][inner_key]+=1\n",
    "\n",
    "\n",
    "\"\"\"Converting counts to probabilities in the two nested dictionaries\n",
    "& also converting the nested dictionaries to outer dictionary with inner sorted lists\n",
    "\"\"\"\n",
    "for key in dict2_tag_follow_tag_:\n",
    "    di = dict2_tag_follow_tag_[key]\n",
    "    s = sum(di.values())\n",
    "    for innkey in di:\n",
    "        di[innkey] /= s\n",
    "    di = di.items()\n",
    "    di = sorted(di,key=lambda x: x[0])\n",
    "    dict2_tag_follow_tag_[key] = di\n",
    "\n",
    "for key in dict2_word_tag:\n",
    "    di = dict2_word_tag[key]\n",
    "    dict_word_tag_baseline[key] = max(di, key=di.get)\n",
    "    s = sum(di.values())\n",
    "    for innkey in di:\n",
    "        di[innkey] /= s\n",
    "    di = di.items()\n",
    "    di = sorted(di,key=lambda x: x[0])\n",
    "    dict2_word_tag[key] = di\n",
    "\n",
    "###Testing Phase###    \n",
    "\n",
    "with open(\"test.txt\", \"r\") as myfile:\n",
    "    te_str = myfile.read()\n",
    "\n",
    "te_li = te_str.split()\n",
    "num_words_test = len(te_li)\n",
    "\n",
    "test_li_words = ['']\n",
    "test_li_words*= num_words_test\n",
    "\n",
    "test_li_tags = ['']\n",
    "test_li_tags*= num_words_test\n",
    "\n",
    "output_li = ['']\n",
    "output_li*= num_words_test\n",
    "\n",
    "output_li_baseline = ['']\n",
    "output_li_baseline*= num_words_test\n",
    "\n",
    "num_errors = 0\n",
    "num_errors_baseline = 0\n",
    "\n",
    "for i in range(num_words_test):\n",
    "    temp_li = te_li[i].split(\"/\")\n",
    "    test_li_words[i] = temp_li[0]\n",
    "    if temp_li[1] in noun_reduced_list:\n",
    "        test_li_tags[i] = 'N'\n",
    "    elif temp_li[1] in verb_reduced_list:\n",
    "        test_li_tags[i] = 'V'\n",
    "    elif temp_li[1] in adjec_reduced_list:\n",
    "        test_li_tags[i] = 'ADJ'\n",
    "    elif temp_li[1] in adv_reduced_list:\n",
    "        test_li_tags[i] = 'ADV'        \n",
    "    elif temp_li[1] in pronoun_reduced_list:\n",
    "        test_li_tags[i] = 'PRO'\n",
    "    else:\n",
    "        test_li_tags[i] = temp_li[1]\n",
    "\n",
    "\n",
    "    output_li_baseline[i] = dict_word_tag_baseline.get(temp_li[0],'')\n",
    "    #If unknown word - tag = 'N'\n",
    "    if output_li_baseline[i]=='':\n",
    "        output_li_baseline[i]='N'\n",
    "\n",
    "    if output_li_baseline[i]!=test_li_tags[i]:\n",
    "        num_errors_baseline+=1\n",
    "    \n",
    "    if i==0:    #Accounting for the 1st word in the test document for the Viterbi\n",
    "        di_transition_probs = dict2_tag_follow_tag_['.']\n",
    "    else:\n",
    "        di_transition_probs = dict2_tag_follow_tag_[output_li[i-1]]\n",
    "        \n",
    "    di_emission_probs = dict2_word_tag.get(test_li_words[i],'')\n",
    "\n",
    "    #If unknown word  - tag = 'N'\n",
    "    if di_emission_probs=='':\n",
    "        output_li[i]='N'\n",
    "        \n",
    "    else:\n",
    "        max_prod_prob = 0\n",
    "        counter_trans = 0\n",
    "        counter_emis =0\n",
    "        prod_prob = 0\n",
    "        while counter_trans < len(di_transition_probs) and counter_emis < len(di_emission_probs):\n",
    "            tag_tr = di_transition_probs[counter_trans][0]\n",
    "            tag_em = di_emission_probs[counter_emis][0]\n",
    "            if tag_tr < tag_em:\n",
    "                counter_trans+=1\n",
    "            elif tag_tr > tag_em:\n",
    "                counter_emis+=1\n",
    "            else:\n",
    "                prod_prob = di_transition_probs[counter_trans][1] * di_emission_probs[counter_emis][1]\n",
    "                if prod_prob > max_prod_prob:\n",
    "                    max_prod_prob = prod_prob\n",
    "                    output_li[i] = tag_tr\n",
    "                    print (\"i=\",i,\" and output=\",output_li[i])\n",
    "                counter_trans+=1\n",
    "                counter_emis+=1    \n",
    "\n",
    "    if output_li[i]=='': #In case there are no matching entries between the transition tags and emission tags, we choose the most frequent emission tag\n",
    "        output_li[i] = max(di_emission_probs,key=itemgetter(1))[0]  \n",
    "        \n",
    "    if output_li[i]!=test_li_tags[i]:\n",
    "        num_errors+=1\n",
    "\n",
    "                    \n",
    "print (\"Fraction of errors (Baseline) :\",(num_errors_baseline/num_words_test))\n",
    "print (\"Fraction of errors (Viterbi):\",(num_errors/num_words_test))\n",
    "\n",
    "\n",
    "\n",
    "print (\"Tags suggested by Baseline Algorithm:\", output_li_baseline)\n",
    "\n",
    "print (\"Tags suggested by Viterbi Algorithm:\", output_li)\n",
    "\n",
    "print (\"Correct tags:\",test_li_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b150c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
