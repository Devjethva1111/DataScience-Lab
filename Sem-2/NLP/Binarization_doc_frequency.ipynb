{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202054dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5783764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1= '''being an at from that are a they be or such for does same were she you the us am been then to we none may other all she how'''\n",
    "d2= '''does with had was she or and has are from an could same be is they must you when the am I you of being do were what such some'''\n",
    "d3= '''any where he who it so would do there they how it she could with a an have we more by this in when or might had you does from'''\n",
    "d4= '''he they more has how for may by same what I here from were a on there at we where does such none could any it with some to do'''\n",
    "d5= '''had many could will some would and I they the must been that such he who she then when are was why in do so where of being it might'''\n",
    "d6= '''might be such he for he none how did I you we because should is will she at where it a the in us been have does any there on'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e257c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Words\tdoc1\tdoc2\tdoc3\tdoc4\tdoc5\tdoc6\t\n",
      "this\t0\t0\t1\t0\t0\t0\t\n",
      "should\t0\t0\t0\t0\t0\t1\t\n",
      "does\t1\t1\t1\t1\t0\t1\t\n",
      "were\t1\t1\t0\t1\t0\t0\t\n",
      "be\t1\t1\t0\t0\t0\t1\t\n",
      "will\t0\t0\t0\t0\t1\t1\t\n",
      "none\t1\t0\t0\t1\t0\t1\t\n",
      "so\t0\t0\t1\t0\t1\t0\t\n",
      "we\t1\t0\t1\t1\t0\t1\t\n",
      "would\t0\t0\t1\t0\t1\t0\t\n",
      "and\t0\t1\t0\t0\t1\t0\t\n",
      "that\t1\t0\t0\t0\t1\t0\t\n",
      "it\t0\t0\t1\t1\t1\t1\t\n",
      "why\t0\t0\t0\t0\t1\t0\t\n",
      "on\t0\t0\t0\t1\t0\t1\t\n",
      "or\t1\t1\t1\t0\t0\t0\t\n",
      "by\t0\t0\t1\t1\t0\t0\t\n",
      "he\t0\t0\t1\t1\t1\t1\t\n",
      "of\t0\t1\t0\t0\t1\t0\t\n",
      "how\t1\t0\t1\t1\t0\t1\t\n",
      "here\t0\t0\t0\t1\t0\t0\t\n",
      "you\t1\t1\t1\t0\t0\t1\t\n",
      "with\t0\t1\t1\t1\t0\t0\t\n",
      "all\t1\t0\t0\t0\t0\t0\t\n",
      "a\t1\t0\t1\t1\t0\t1\t\n",
      "the\t1\t1\t0\t0\t1\t1\t\n",
      "from\t1\t1\t1\t1\t0\t0\t\n",
      "is\t0\t1\t0\t0\t0\t1\t\n",
      "I\t0\t1\t0\t1\t1\t1\t\n",
      "any\t0\t0\t1\t1\t0\t1\t\n",
      "to\t1\t0\t0\t1\t0\t0\t\n",
      "same\t1\t1\t0\t1\t0\t0\t\n",
      "where\t0\t0\t1\t1\t1\t1\t\n",
      "are\t1\t1\t0\t0\t1\t0\t\n",
      "has\t0\t1\t0\t1\t0\t0\t\n",
      "might\t0\t0\t1\t0\t1\t1\t\n",
      "do\t0\t1\t1\t1\t1\t0\t\n",
      "more\t0\t0\t1\t1\t0\t0\t\n",
      "did\t0\t0\t0\t0\t0\t1\t\n",
      "who\t0\t0\t1\t0\t1\t0\t\n",
      "there\t0\t0\t1\t1\t0\t1\t\n",
      "what\t0\t1\t0\t1\t0\t0\t\n",
      "had\t0\t1\t1\t0\t1\t0\t\n",
      "some\t0\t1\t0\t1\t1\t0\t\n",
      "when\t0\t1\t1\t0\t1\t0\t\n",
      "they\t1\t1\t1\t1\t1\t0\t\n",
      "being\t1\t1\t0\t0\t1\t0\t\n",
      "such\t1\t1\t0\t1\t1\t1\t\n",
      "must\t0\t1\t0\t0\t1\t0\t\n",
      "she\t1\t1\t1\t0\t1\t1\t\n",
      "then\t1\t0\t0\t0\t1\t0\t\n",
      "been\t1\t0\t0\t0\t1\t1\t\n",
      "may\t1\t0\t0\t1\t0\t0\t\n",
      "was\t0\t1\t0\t0\t1\t0\t\n",
      "am\t1\t1\t0\t0\t0\t0\t\n",
      "an\t1\t1\t1\t0\t0\t0\t\n",
      "other\t1\t0\t0\t0\t0\t0\t\n",
      "many\t0\t0\t0\t0\t1\t0\t\n",
      "could\t0\t1\t1\t1\t1\t0\t\n",
      "because\t0\t0\t0\t0\t0\t1\t\n",
      "at\t1\t0\t0\t1\t0\t1\t\n",
      "in\t0\t0\t1\t0\t1\t1\t\n",
      "us\t1\t0\t0\t0\t0\t1\t\n",
      "have\t0\t0\t1\t0\t0\t1\t\n",
      "for\t1\t0\t0\t1\t0\t1\t\n"
     ]
    }
   ],
   "source": [
    "# List of documents\n",
    "documents = [d1, d2, d3, d4, d5, d6]\n",
    "\n",
    "# Function to create the table\n",
    "def create_table(documents):\n",
    "    # Initialize an empty set for unique words\n",
    "    unique_words = set()\n",
    "\n",
    "    # Add unique words from each document to the set\n",
    "    for doc in documents:\n",
    "        unique_words.update(doc.split())\n",
    "\n",
    "    # Creating the table\n",
    "    table = {}\n",
    "    for word in unique_words:\n",
    "        table[word] = [1 if word in doc.split() else 0 for doc in documents]\n",
    "    return table\n",
    "\n",
    "# Create the table\n",
    "table = create_table(documents)\n",
    "\n",
    "# Print the table\n",
    "print(\"Unique Words\\t\", end=\"\")\n",
    "for i in range(1, 7):\n",
    "    print(f\"doc{i}\\t\", end=\"\")\n",
    "print()\n",
    "\n",
    "for word, occurrences in table.items():\n",
    "    print(f\"{word}\\t\", end=\"\")\n",
    "    for occurrence in occurrences:\n",
    "        print(f\"{occurrence}\\t\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05f9355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f4a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac2a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40f4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unique Words  doc1  doc2  doc3  doc4  doc5  doc6\n",
      "0          this     0     0     1     0     0     0\n",
      "1        should     0     0     0     0     0     1\n",
      "2          does     1     1     1     1     0     1\n",
      "3          were     1     1     0     1     0     0\n",
      "4            be     1     1     0     0     0     1\n",
      "..          ...   ...   ...   ...   ...   ...   ...\n",
      "60           at     1     0     0     1     0     1\n",
      "61           in     0     0     1     0     1     1\n",
      "62           us     1     0     0     0     0     1\n",
      "63         have     0     0     1     0     0     1\n",
      "64          for     1     0     0     1     0     1\n",
      "\n",
      "[65 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Document strings\n",
    "d1 = '''being an at from that are a they be or such for does same were she you the us am been then to we none may other all she how'''\n",
    "d2 = '''does with had was she or and has are from an could same be is they must you when the am I you of being do were what such some'''\n",
    "d3 = '''any where he who it so would do there they how it she could with a an have we more by this in when or might had you does from'''\n",
    "d4 = '''he they more has how for may by same what I here from were a on there at we where does such none could any it with some to do'''\n",
    "d5 = '''had many could will some would and I they the must been that such he who she then when are was why in do so where of being it might'''\n",
    "d6 = '''might be such he for he none how did I you we because should is will she at where it a the in us been have does any there on'''\n",
    "\n",
    "# List of document strings\n",
    "documents = [d1, d2, d3, d4, d5, d6]\n",
    "\n",
    "# Initialize an empty set for unique words\n",
    "unique_words = set()\n",
    "\n",
    "# Add unique words from each document to the set\n",
    "for doc in documents:\n",
    "    unique_words.update(doc.split())\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=['Unique Words'] + [f\"doc{i}\" for i in range(1, 7)])\n",
    "\n",
    "# Iterate over unique words to populate the DataFrame\n",
    "for word in unique_words:\n",
    "    occurrences = [1 if word in doc.split() else 0 for doc in documents]\n",
    "    df.loc[len(df)] = [word] + occurrences\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbef4513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the word to check: be\n",
      "Enter the document number (1-6): 5\n",
      "The word 'be' is not present in document 5.\n"
     ]
    }
   ],
   "source": [
    "def check_word_presence():\n",
    "    word = input(\"Enter the word to check: \")\n",
    "    doc_number = int(input(\"Enter the document number (1-6): \"))\n",
    "    presence = \"present\" if word in df['Unique Words'].values and df[f\"doc{doc_number}\"][df[df['Unique Words'] == word].index[0]] == 1 else \"not present\"\n",
    "    print(f\"The word '{word}' is {presence} in document {doc_number}.\")\n",
    "\n",
    "# Example usage\n",
    "check_word_presence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5bd5861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the word to check: be\n",
      "The word 'be' is present in document 1.\n",
      "The word 'be' is present in document 2.\n",
      "The word 'be' is present in document 6.\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter the word to check: \")\n",
    "for i in range(1, 7):\n",
    "    if word in df['Unique Words'].values and df[f\"doc{i}\"][df[df['Unique Words'] == word].index[0]] == 1:\n",
    "        print(f\"The word '{word}' is present in document {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cae0840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "a = input()\n",
    "for i in range(1,7):\n",
    "    if word in df[\"Unique Words\"].values:\n",
    "        print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f1ddfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the word to check: be\n",
      "The word 'be' is present in document 1.\n",
      "The word 'be' is present in document 2.\n",
      "The word 'be' is present in document 6.\n"
     ]
    }
   ],
   "source": [
    "word = input(\"Enter the word to check: \")\n",
    "for i in range(1, 7):\n",
    "    if word in df['Unique Words'].values and df[f\"doc{i}\"][df[df['Unique Words'] == word].index[0]] == 1:\n",
    "        print(f\"The word '{word}' is present in document {i}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a52ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dictionary to store the document names where each word is present\n",
    "# word_presence = {}\n",
    "\n",
    "# # Iterate over each document\n",
    "# for doc_num, doc_content in enumerate(documents, start=1):\n",
    "#     # Split the document content into words\n",
    "#     words = doc_content.split()\n",
    "#     # Iterate over each word in the document\n",
    "#     for word in words:\n",
    "#         # Check if the word is already present in the dictionary\n",
    "#         if word in word_presence:\n",
    "#             # If present, append the current document name to the list\n",
    "#             word_presence[word].append(f\"doc{doc_num}\")\n",
    "#         else:\n",
    "#             # If not present, create a new list with the current document name\n",
    "#             word_presence[word] = [f\"doc{doc_num}\"]\n",
    "\n",
    "# # Print document names for each word\n",
    "# for word, docs in word_presence.items():\n",
    "#     print(f\"The word '{word}' is present in the following document(s): {', '.join(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e7673f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Word                 Documents\n",
      "0     being        [doc1, doc2, doc5]\n",
      "1        an        [doc1, doc2, doc3]\n",
      "2        at        [doc1, doc4, doc6]\n",
      "3      from  [doc1, doc2, doc3, doc4]\n",
      "4      that              [doc1, doc5]\n",
      "..      ...                       ...\n",
      "60     will              [doc5, doc6]\n",
      "61      why                    [doc5]\n",
      "62      did                    [doc6]\n",
      "63  because                    [doc6]\n",
      "64   should                    [doc6]\n",
      "\n",
      "[65 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the document names where each word is present\n",
    "word_presence = {}\n",
    "\n",
    "# Iterate over each document\n",
    "for doc_num, doc_content in enumerate(documents, start=1):\n",
    "    # Split the document content into words\n",
    "    words = doc_content.split()\n",
    "    # Iterate over each word in the document\n",
    "    for word in words:\n",
    "        # Check if the word is already present in the dictionary\n",
    "        if word in word_presence:\n",
    "            # If present, append the current document name to the list\n",
    "            word_presence[word].append(f\"doc{doc_num}\")\n",
    "        else:\n",
    "            # If not present, create a new list with the current document name\n",
    "            word_presence[word] = [f\"doc{doc_num}\"]\n",
    "\n",
    "# Create a pandas DataFrame from the word_presence dictionary\n",
    "df = pd.DataFrame(word_presence.items(), columns=['Word', 'Documents'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5d5d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to document_word_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('document_word_matrix.csv')\n",
    "print(\"DataFrame saved to document_word_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8a1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda54574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
